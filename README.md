# Fun Papers
papers from graphics, vision, and hci

## SIGGRAPH 
* `SIGGRAPHASIA2019` Mitsuba 2: A Retargetable Forward and Inverse Renderer [[link]](https://rgl.epfl.ch/publications/NimierDavidVicini2019Mitsuba2)
* `SIGGRAPHASIA2019` Animating Landscape [[link]](http://www.npal.cs.tsukuba.ac.jp/~endo/projects/AnimatingLandscape/)
* `SIGGRAPHASIA2019` 3D Ken Burns Effect from a Single Image [[link]](http://sniklaus.com/papers/kenburns)
* `SIGGRAPHASIA2019` DeepRemaster [[link]](http://iizuka.cs.tsukuba.ac.jp/projects/remastering/en/index.html)[[code]](https://github.com/satoshiiizuka/siggraphasia2019_remastering)
* `SIGGRAPHASIA2019` Write-A-Video: Computational Video Montage from Themed Text [[link]](http://www.faculty.idc.ac.il/arik/site/writeVideo.asp)
* `SIGGRAPHASIA2019` Language-based Colorization of Scene Sketches
 [[link]](http://sweb.cityu.edu.hk/hongbofu/doc/language-based_sketch_colorization_SA19.pdf)[[code]](https://github.com/SketchyScene/SketchySceneColorization)
---
* `SIGGRAPH2019` Semantic Photo Manipulation With a Generative Image Prio [[link]](http://ganpaint.io/)
* `SIGGRAPH2019` TileGAN: Synthesis of Large-Scale Non-Homogeneous Textures  [[code]](https://github.com/afruehstueck/tileGAN)
* `SIGGRAPH2019` Progressive Color Transfer with Dense Semantic Correspondences [[link]](https://arxiv.org/pdf/1710.00756.pdf)
* `SIGGRAPH2019` The Face of Art: Landmark Detection and Geometric Style in Portraits [[link]](http://www.faculty.idc.ac.il/arik/site/foa/face-of-art.asp)
* `SIGGRAPH2019` Distortion-Free Wide-Angle Portraits on Camera Phones [[link]](http://people.csail.mit.edu/yichangshih/wide_angle_portrait/)
* `SIGGRAPH2019` Interactive and Automatic Navigation for 360° Video Playback [[link]](https://vclab.dgist.ac.kr/interactive360/)
* `SIGGRAPH2019` Joint Stabilization and Direction of 360° Videos [[link]](https://dl.acm.org/citation.cfm?doid=3313807.3211889)
* `SIGGRAPH2019` Text-based Editing of Talking-head Video[[link]](https://www.ohadf.com/projects/text-based-editing/)
* `SIGGRAPH2019` Single Image Portrait Relighting [[link]](https://arxiv.org/pdf/1905.00824.pdf)
* `SIGGRAPH2019` Local Light Field Fusion: Practical View Synthesis 
with Prescriptive Sampling Guidelines [[link]](http://people.eecs.berkeley.edu/~bmild/llff/) [[code]](https://github.com/Fyusion/LLFF)
* `SIGGRAPH2019` Multi-view Relighting using a Geometry-Aware Network [[link]](https://repo-sam.inria.fr/fungraph/deep-relighting/)
* `SIGGRAPH2019` Learning Character-Agnostic Motion for Motion Retargeting in 2D [[link]](https://motionretargeting2d.github.io/)[[code]](https://github.com/ChrisWu1997/2D-Motion-Retargeting)
* `SIGGRAPH2019` Synthetic Defocus and Look-Ahead Autofocus for Casual Videograph [[link]](https://ceciliavision.github.io/vid-auto-focus/)
* `SIGGRAPH2019` Video Extrapolation Using Neighboring Frames [[link]](https://vml.kaist.ac.kr/main/international/individual/157)
* `SIGGRAPH2019` Physics-based Full-body Soccer Motion Control for Dribbling and Shooting [[link]](https://vml.kaist.ac.kr/main/international/individual/156)
* `SIGGRAPH2019` Neural Rendering and Reenactment of Human Actor Videos [[link]](http://gvv.mpi-inf.mpg.de/projects/wxu/HumanReenactment/)
* `SIGGRAPH2019` Deferred Neural Rendering: Image Synthesis using Neural Textures [[link]](https://niessnerlab.org/projects/thies2019neural.html)
* `SIGGRAPH2019` Deep View Synthesis from Sparse Photometric Images [[link]](http://cseweb.ucsd.edu/~ravir/zexiangview.pdf)
* `SIGGRAPH2019` Stylizing Video by Example [[link]](https://dcgi.fel.cvut.cz/home/sykorad/ebsynth.html)
---
* `SIGGRAPH2018` Non-stationary Texture Synthesis by Adversarial Expansion [[link]](http://vcc.szu.edu.cn/research/2018/TexSyn)[[code]](https://github.com/jessemelpolio/non-stationary_texture_syn)
* `SIGGRAPH2018` Semantic Soft Segmentation [[link]](http://people.inf.ethz.ch/aksoyy/sss/)
* `SIGGRAPH2018` Stereo Magnification: Learning View Synthesis using Multiplane Images [[link]](https://people.eecs.berkeley.edu/~tinghuiz/projects/mpi/)
* `SIGGRAPH2018` Instant 3D Photography [[link]](http://visual.cs.ucl.ac.uk/pubs/instant3d/)
* `SIGGRAPH2018` FaceShop: Deep Sketch-based Face Image Editing [[link]](https://arxiv.org/pdf/1804.08972.pdf)
* `SIGGRAPH2018` Deep Image-Based Relighting from Optimal Sparse Samples [[link]](http://cseweb.ucsd.edu/~viscomp/projects/SIG18Relighting/)
* `SIGGRAPH2018` Deep Video Portraits [[link]](https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html)
* `SIGGRAPH2018` ToonSynth: Example-Based Synthesis of Hand-Colored Cartoon Animations [[link]](http://dcgi.fel.cvut.cz/home/sykorad/toonsynth.html)
* `SIGGRAPH2018` Robust Solving of Optical Motion Capture Data by Denoising [[link]](http://montreal.ubisoft.com/en/robust-solving-of-optical-motion-capture-data-by-denoising/)
* `SIGGRAPH2018` MonoPerfCap: Human Performance Capture from Monocular Video [[link]](http://gvv.mpi-inf.mpg.de/projects/wxu/MonoPerfCap/)

---
* `SIGGRAPH2017` Computational Video Editing for Dialogue-Driven Scenes [[link]](http://graphics.stanford.edu/papers/roughcut/)
* `SIGGRAPH2017` Unmixing-Based Soft Color Segmentation for Image Manipulation [[link]](http://people.inf.ethz.ch/aksoyy/scs/)
* `SIGGRAPH2017` Interactive High-Quality Green-Screen Keying via Color Unmixing [[link]](http://people.inf.ethz.ch/aksoyy/keying/)
* `SIGGRAPH2016` Perspective-aware Manipulation of Portrait Photos [[link]](https://gfx.cs.princeton.edu/pubs/Fried_2016_PMO/index.php)
* `SIGGRAPH2014` 3D Object Manipulation in a Single Photograph using Stock 3D Models[[link]](http://www.cs.cmu.edu/~om3d/)[[code]](http://www.cs.cmu.edu/~om3d/)
* `SIGGRAPH2010` Video Tapestries with Continuous Temporal Zoom [[link]](https://gfx.cs.princeton.edu/pubs/Barnes_2010_VTW/index.php)
* `SIGGRAPH2006` Schematic Storyboarding for Video Visualization and Editing [[link]](https://grail.cs.washington.edu/projects/storyboards/)
* `SIGGRAPH2005` Interactive Video Cutout [[link]](http://juew.org/projects/VideoCutout/VideoCutout.htm)
---

## GRAPHICS

* Stylizing Animation By Example[[link]](http://graphics.pixar.com/library/ByExampleStylization/paper.pdf)

### image2video
* Vid2Game: Controllable Characters Extracted from Real-World Videos
* DynamoNet: Dynamic Action and Motion Network

### inpainting
* `ICCV2019` Boundless: Generative Adversarial Networks for Image Extension
* `ICCV2019` Attention on Attention for Image Captioning
* `CVPR2019` Learning Pyramid-Context Encoder Network for High-Quality Image Inpainting [[code]](https://github.com/researchmm/PEN-Net-for-Inpainting)
* `CVPR2019` Deep Flow-Guided Video Inpainting [[code]](https://github.com/nbei/Deep-Flow-Guided-Video-Inpainting)
* `CVPR2019` Deep Video Inpainting [[code]](https://github.com/mcahny/Deep-Video-Inpainting)
* `CVPR2019` Foreground-Aware Image Inpainting
* `CVPR2019` PEPSI : Fast Image Inpainting With Parallel Decoding Network
* `arixiv2019` PEPSI++: Fast and Lightweight Network for Image Inpainting
* `CVPR2019` Coordinate-Based Texture Inpainting for Pose-Guided Human Image Generation
* `CVPR2019` Wide-Context Semantic Image Extrapolation [[code]](https://github.com/shepnerd/outpainting_srn)
* `NeurIPS2018` Image Inpainting via Generative Multi-column Convolutional Neural Networks [[code]](https://github.com/shepnerd/inpainting_gmcnn)
* `CVPR2018` Generative Image Inpainting with Contextual Attention [[code]](https://github.com/JiahuiYu/generative_inpainting)
* `ECCV2018` Image Inpainting for Irregular Holes Using Partial Convolutions [[code]](https://github.com/NVIDIA/partialconv) [[code2]](https://github.com/MathiasGruber/PConv-Keras)
* `Arixiv2018` Free-Form Image Inpainting with Gated Convolution [[link]](http://jiahuiyu.com/deepfill2/)[[code]](https://github.com/JiahuiYu/generative_inpainting)
* `SIGGRAPH2017` Globally and Locally Consistent Image Completion [[link]](http://iizuka.cs.tsukuba.ac.jp/projects/completion/en/)[[code]](https://github.com/satoshiiizuka/siggraph2017_inpainting)


### image manipulation and editing
* SliderGAN: Synthesizing Expressive Face Images by Sliding 3D Blendshape Parameters [[link]](https://arxiv.org/abs/1805.09313)
* FSGAN: Subject Agnostic Face Swapping and Reenactment [[link]](https://nirkin.com/fsgan/)
* SinGAN: Learning a Generative Model from a Single Natural Image [[code]](https://github.com/tamarott/SinGAN)[[code2]](https://github.com/FriedRonaldo/SinGAN)
* LADN: Local Adversarial Disentangling Network for Facial Makeup and De-Makeup
* Fast Deep Matting for Portrait Animation on Mobile Phone [[link]](https://arxiv.org/pdf/1707.08289.pdf)[[code]](https://github.com/ofirlevy/FastMattingPortrait)
* `CVPR2017` Deep Image Matting [[link]](https://arxiv.org/pdf/1703.03872.pdf)[[code]](https://github.com/Joker316701882/Deep-Image-Matting)[[code2]](https://github.com/foamliu/Deep-Image-Matting)
* FaceShapeGene: A Disentangled Shape Representation for Flexible Face Image Editing
* `ICCV2019`Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation [[link]](http://www.robots.ox.ac.uk/~tvg/publications/2019/ICCV_ISF_camera_ready.pdf)
### generative model
* `CVPR2019` Semantic Image Synthesis with Spatially-Adaptive Normalization [[link]](https://arxiv.org/abs/1903.07291)[[code]](https://github.com/NVlabs/SPADE) [[code2]](https://github.com/taki0112/SPADE-Tensorflow)
* `ICCV2019`Specifying Object Attributes and Relations in Interactive Scene Generation [[code]](https://github.com/ashual/scene_generation)
### style transfer
* `ICCV2017` Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization [[link]](https://arxiv.org/abs/1703.06868)[[code]](https://github.com/xunhuang1995/AdaIN-style)

### inverse rendering
* Lifting AutoEncoders: Unsupervised Learning of a Fully-Disentangled 3D Morphable Model using Deep Non-Rigid Structure from Motion

### image based rendering
* `CVPR2019`  Neural Rerendering in the Wild [[link]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Meshry_Neural_Rerendering_in_the_Wild_CVPR_2019_paper.pdf)[[]]
* `Arxiv2019` NVS Machines: Learning Novel View Synthesis with Fine-grained View Control [[link]](https://arxiv.org/pdf/1901.01880.pdf)
* HoloGAN: Unsupervised learning of 3D representations from natural images [[link]](https://arxiv.org/abs/1904.01326)
* `CVPR2019` Pushing the Boundaries of View Extrapolation with Multiplane Images [[link]](http://cseweb.ucsd.edu/~ravir/MPI_pratul.pdf)
* `EECV2018` Multi-view to Novel view: Synthesizing Novel Views with Self-Learned Confidence [[link]](https://shaohua0116.github.io/Multiview2Novelview/)[[code]](https://github.com/shaohua0116/Multiview2Novelview)


---
## START REPORT [[link]](https://sites.google.com/site/drminchen/cgf-info/cgf-stars)
* A Survey on Data-Driven Video Completion
* State of the Art Report on Video-Based Graphics andVideo Visualization
* A Comparative Review of Tone-Mapping Algorithms for High Dynamic Range Video
* Intrinsic Decompositions for Image Editing
* The State of the Art in Integrating Machine Learning into Visual Analytics
* A Comprehensive Survey on Sampling-Based Image Matting
---

## VISION

* `ICCV2019` SinGAN: Learning a Generative Model from a Single Natural Image [[code]](https://github.com/tamarott/SinGAN)
* `ICCV2019` Specifying Object Attributes and Relations in Interactive Scene Generation [[code]](https://github.com/ashual/scene_generation)
* `ICCV2019` FaceForensics++: Learning to Detect Manipulated Facial Images [[code]](https://github.com/ondyari/FaceForensics)
* `ICCV2019` StructureFlow: Image Inpainting via Structure-Aware Appearance Flow [[code]](https://github.com/RenYurui/StructureFlow)
* `ICCV2019` Generative Adversarial Training for Weakly Supervised Cloud Matting [[link]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Zou_Generative_Adversarial_Training_for_Weakly_Supervised_Cloud_Matting_ICCV_2019_paper.pdf)
* `ICCV2019` Unsupervised Video Interpolation Using Cycle Consistency [[link]]()
* `ICCV2019` Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation [[link]]()
* `ICCV2019` Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation	[[link]]()
* `ICCV2019` Image Aesthetic Assessment Based on Pairwise Comparison A Unified Approach to Score Regression, Binary Classification, and Personalization [[link]]()
* `ICCV2019` Exploring Randomly Wired Neural Networks for Image Recognition[[link]]()
* `ICCV2019` Searching for MobileNetV3 [[link]]()
* `ICCV2019` Deep Non-Rigid Structure From Motion	[[link]]()
* `ICCV2019` SC-FEGAN: Face Editing Generative Adversarial Network With User’s Sketch and Color	[[link]]()
* `ICCV2019` MultiSeg: Semantically Meaningful, Scale-Diverse Segmentations from Minimal User Input [[link]]()
* `ICCV2019` Learning to Reconstruct 3D Human Pose and Shape via Model-Fitting in the Loop [[link]]()
* `ICCV2019` PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitizatio[[link]]()
* `ICCV2019` Learning to Jointly Generate and Separate Reflections [[link]]()
* `ICCV2019` Mask-ShadowGAN: Learning to Remove Shadows From Unpaired Data [[link]]()
* `ICCV2019` Learning Deep Priors for Image Dehazing [[link]]()
* `ICCV2019` An Internal Learning Approach to Video Inpainting [[link]]()
* `ICCV2019` Deep CG2Real: Synthetic-to-Real Translation via Image Disentanglement	[[link]]()
* `ICCV2019` Image Generation From Small Datasets via Batch Statistics Adaptation [[link]]()
* `ICCV2019` Unsupervised Robust Disentangling of Latent Characteristics for Image Synthesis [[link]]()
* `ICCV2019` Lifelong GAN: Continual Learning for Conditional Image Generation [[link]]()
* `ICCV2019` Toward Real-World Single Image Super-Resolution: A New Benchmark and a New Model [[link]]()
* `ICCV2019` RankSRGAN: Generative Adversarial Networks With Ranker for Image Super-Resolution [[link]]()
* `ICCV2019` Progressive Fusion Video Super-Resolution Network via Exploiting Non-Local Spatio-Temporal Correlations [[link]]()
* `ICCV2019` Deep SR-ITM: Joint Learning of Super-Resolution and Inverse Tone-Mapping for 4K UHD HDR Applications [[link]]()
* `ICCV2019` Real Image Denoising With Feature Attention [[link]]()
* `ICCV2019` Seeing Motion in the Dark [[link]]()
* `ICCV2019` Toward Real-World Single Image Super-Resolution: A New Benchmark and a New Model[[link]]()
* `ICCV2019` Wavelet Domain Style Transfer for an Effective Perception-Distortion Tradeoff in Single Image Super-Resolution[[link]]()
* `ICCV2019` Deep SR-ITM: Joint Learning of Super-Resolution and Inverse Tone-Mapping for 4K UHD HDR Applications [[link]]()
* `ICCV2019` DSIC: Deep Stereo Image Compression [[link]]()
* `ICCV2019` Seeing Motion in the Dark[[link]]()
* `ICCV2019` Coherent Semantic Attention for Image Inpainting [[link]]()
* `ICCV2019` Monocular Neural Image Based Rendering With Continuous View Control[[link]]()
* `ICCV2019` Neural-Guided RANSAC: Learning Where to Sample Model Hypotheses[[link]]()
* `ICCV2019` Compositional Video Prediction [[link]]()
* `ICCV2019` Diverse Image Synthesis From Semantic Layouts via Conditional IMLE[[link]]()
* `ICCV2019` Monocular Neural Image Based Rendering With Continuous View Control[[link]]()
* `ICCV2019` A Dataset of Multi-Illumination Images in the Wild[[link]]()
* `ICCV2019` Program-Guided Image Manipulators [[link]]()
* `ICCV2019` Multi-View Image Fusion [[link]]()
* `ICCV2019` Unsupervised 3D Reconstruction Networks [[link]]()
* `ICCV2019` Online Unsupervised Learning of the 3D Kinematic Structure of Arbitrary Rigid Bodies [[link]]()
* `ICCV2019` AutoGAN: Neural Architecture Search for Generative Adversarial Networks[[link]]()
* `ICCV2019` Indices Matter: Learning to Index for Deep Image Matting[[link]]()
* `ICCV2019` Context-Aware Image Matting for Simultaneous Foreground and Alpha Estimation[[link]]()
* `ICCV2019` Deep Restoration of Vintage Photographs From Scanned Halftone Prints [[link]]()
* `ICCV2019` [[link]]()



* `ICCV2019` Convolutional Sequence Generation for Skeleton-Based Action Synthesis [[link]]()
* `ICCV2019` Onion-Peel Networks for Deep Video Completion [[link]]()
* `ICCV2019` Copy-and-Paste Networks for Deep Video Inpainting [[link]]()
* `ICCV2019` Content and Style Disentanglement for Artistic Style Transfer [[link]]()
31
54
90
94
113
119
122
127
132
143
150~153

* `Arixiv2019` Few-Shot Adversarial Learning of Realistic Neural Talking Head Models
* `CVPR2019` Deep Image Prior[[link]](https://dmitryulyanov.github.io/deep_image_prior)[[code]](https://github.com/DmitryUlyanov/deep-image-prior)
* `CVPR2016` Spatiotemporal Bundle Adjustment
* `CVPR2015` Finding Distractors In Images [[link]](http://openaccess.thecvf.com/content_cvpr_2015/papers/Fried_Finding_Distractors_In_2015_CVPR_paper.pdf)

## HCI

* `CHI2019` POSE-GUIDED LEVEL DESIGN [[link]](http://blogs.umb.edu/yongqizhang001/pose-guided-level-design/)
* `CHI2016` Airways: Optimization-Based Planning of Quadrotor Trajectories according to High-Level User Goals [[link]](https://ait.ethz.ch/projects/2016/airways/downloads/paper1570.pdf)[[video]](https://www.youtube.com/watch?v=6krfPE0ADdw)
* `UIST2010` Cosaliency: where people look when comparing images [[link]](http://graphics.stanford.edu/papers/cosaliency/)



## Notes from conferences
* Practical Least-Squares for Computer Graphics [[link]](http://graphics.stanford.edu/~jplewis/lscourse/ls.pdf)
